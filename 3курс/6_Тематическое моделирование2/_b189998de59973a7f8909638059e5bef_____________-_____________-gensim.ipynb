{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пример использования библиотеки gensim для тематического моделирования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такая полезная теорема Байеса! :)\n",
    "\n",
    "![comic1](http://imgs.xkcd.com/comics/seashell.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DVtest\\AppData\\Local\\Continuum\\anaconda2\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем данные в формте UCI Bag of Words\n",
    "data = corpora.UciCorpus(\"docword.xkcd.txt\", \"vocab.xkcd.txt\")\n",
    "dictionary = data.create_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 32.6 s\n"
     ]
    }
   ],
   "source": [
    "# обучение модель\n",
    "%time ldamodel = models.ldamodel.LdaModel(data, id2word=dictionary, num_topics=5, passes=20, alpha=1.25, eta=1.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение модели\n",
    "ldamodel.save(\"ldamodel_xkcd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка модели\n",
    "ldamodel = models.ldamodel.LdaModel.load(\"ldamodel_xkcd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0 : 0.005*\"line\" + 0.003*\"graph\" + 0.003*\"labeled\" + 0.002*\"text\" + 0.002*\"title\" + 0.002*\"exhibit\" + 0.002*\"day\" + 0.002*\"number\" + 0.002*\"human\" + 0.001*\"point\"\n",
      "Topic 1 : 0.024*\"man\" + 0.012*\"text\" + 0.010*\"title\" + 0.010*\"woman\" + 0.009*\"guy\" + 0.007*\"person\" + 0.006*\"one\" + 0.006*\"girl\" + 0.005*\"just\" + 0.005*\"hat\"\n",
      "Topic 2 : 0.014*\"person\" + 0.002*\"one\" + 0.002*\"map\" + 0.002*\"text\" + 0.002*\"page\" + 0.002*\"title\" + 0.002*\"two\" + 0.001*\"within\" + 0.001*\"error\" + 0.001*\"island\"\n",
      "Topic 3 : 0.002*\"wait\" + 0.002*\"sagal\" + 0.002*\"peter\" + 0.001*\"gliese\" + 0.001*\"bag\" + 0.001*\"dont\" + 0.001*\"planet\" + 0.001*\"hatboy\" + 0.001*\"destroy\" + 0.001*\"strip\"\n",
      "Topic 4 : 0.001*\"link\" + 0.001*\"jelly\" + 0.001*\"bean\" + 0.001*\"list\" + 0.001*\"acne\" + 0.001*\"goggles\" + 0.001*\"found\" + 0.001*\"005\" + 0.001*\"leopard\" + 0.001*\"flu\"\n"
     ]
    }
   ],
   "source": [
    "# выводим топы слов\n",
    "for t, top_words in ldamodel.print_topics(num_topics=10, num_words=10):\n",
    "    print \"Topic\", t, \":\", top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351.21947005937795\n"
     ]
    }
   ],
   "source": [
    "# Вычисляем логарифм перплексии и немного преобразуем, чтобы привести к общепринятому виду\n",
    "perplexity = ldamodel.log_perplexity(list(data))\n",
    "print 2**(-perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "351.2194831737095"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perp = ldamodel.bound(data)\n",
    "2**(-perp/float(87409))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавление в модель новых документов, содержащихся в новом корупсе data2\n",
    "ldamodel.update(data2, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.060360584),\n",
       " (1, 0.7453071),\n",
       " (2, 0.08312965),\n",
       " (3, 0.05690859),\n",
       " (4, 0.054294042)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Получение распределения тем для конкретного документа\n",
    "doc = list(data)[0]\n",
    "ldamodel.get_document_topics(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эти люди не знают про тематические модели:\n",
    "\n",
    "![comic2](http://imgs.xkcd.com/comics/the_problem_with_wikipedia.png) | ![comic3](http://imgs.xkcd.com/comics/mystery_news.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
